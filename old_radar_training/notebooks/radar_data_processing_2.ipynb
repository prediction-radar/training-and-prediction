{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_CuH59UEqr-",
        "outputId": "027d669c-0757-4ea7-df52-86749163a14f"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "def download_csv_files(folder_url, destination_folder, start_time, end_time):\n",
        "\n",
        "  try:\n",
        "\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "      os.makedirs(destination_folder)\n",
        "\n",
        "    # Delete old files\n",
        "    for filename in os.listdir(destination_folder):\n",
        "      file_path = os.path.join(destination_folder, filename)\n",
        "      try:\n",
        "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "              os.unlink(file_path)\n",
        "          elif os.path.isdir(file_path):\n",
        "              shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "\n",
        "    # Get the list of files in the folder\n",
        "    response = requests.get(folder_url)\n",
        "    data = bs.BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    csv_files = data.find_all(\"a\", href=lambda href: href and href.endswith(\".csv\"))\n",
        "\n",
        "    # Filter CSV files based on time range\n",
        "    filtered_files = []\n",
        "    for file_name in csv_files:\n",
        "        csv_filename = file_name['href'].split('/')[-1]\n",
        "        try:\n",
        "            # Parse the filename to extract the creation or modification time\n",
        "            file_time_str = csv_filename.split('_')[0]  # Assuming the time is in the first part\n",
        "            file_time = datetime.datetime.strptime(file_time_str, '%d-%m-%Y-%H%M')\n",
        "            if start_time <= file_time <= end_time:\n",
        "                filtered_files.append(file_name)\n",
        "        except ValueError as e:\n",
        "            # Handle parsing errors (e.g., invalid filename format)\n",
        "            print(f\"Error parsing filename: {csv_filename}, {e.args[0]}\")\n",
        "\n",
        "    for file_name in filtered_files:\n",
        "      csv_url = file_name['href']  # Get the CSV file URL\n",
        "      csv_filename = csv_url.split('/')[-1]  # Extract the filename\n",
        "      link = folder_url + csv_filename\n",
        "      destination_link = os.path.join(destination_folder, csv_filename)\n",
        "\n",
        "      response = requests.get(link)\n",
        "      with open(destination_link, 'wb') as f:\n",
        "         f.write(response.content)\n",
        "\n",
        "    print(\"Downloading finished, outcome unknown.\")\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading files: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# Initiate download of files\n",
        "folder_url = \"http://69.48.179.226/csv_files/\"  # Replace with the actual folder URL\n",
        "destination_folder = \"csv_files\"  # Replace with the desired destination folder\n",
        "start_time = datetime.datetime(2024, 9, 13, 14, 28)\n",
        "end_time = datetime.datetime(2024, 9, 13, 15, 28)\n",
        "\n",
        "download_csv_files(folder_url, destination_folder, start_time, end_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combines multiple CSV files into one.\n",
        "def combine_csv_files(input_folder, output_file):\n",
        "  \n",
        "    # Get a list of all CSV files in the input folder\n",
        "    csv_files = glob.glob(input_folder + \"/*.csv\")\n",
        "\n",
        "    # Initialize an empty list to store DataFrames\n",
        "    dataframes = []\n",
        "\n",
        "    # Iterate through each CSV file\n",
        "    for file in csv_files:\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        df = df.rename(columns={'time': 'dateTime'})\n",
        "        df = df.rename(columns={'unknown': 'reflectivity'})\n",
        "\n",
        "        # Select the desired columns\n",
        "        df = df[['dateTime', 'latitude', 'longitude', 'reflectivity']]\n",
        "\n",
        "        # Append the DataFrame to the list\n",
        "        dataframes.append(df)\n",
        "\n",
        "    # Concatenate all DataFrames into one\n",
        "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a CSV file\n",
        "    combined_df.to_csv(output_file, index=False)\n",
        "\n",
        "input_folder = \"csv_files\"\n",
        "output_file = \"combined_data.csv\"\n",
        "\n",
        "combine_csv_files(input_folder, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "nRaN7EsWE-Na",
        "outputId": "5c3c4f25-e9a2-4ce3-c089-ab0fd28c4e89"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(precision=15)\n",
        "\n",
        "data = pd.read_csv('combined_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1ppnxhzYN56N",
        "outputId": "5b85da42-b0c9-45b0-8f0b-b0da27607fb1"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "XmeQ2XVAdNFn",
        "outputId": "d9c1464a-89b3-4fab-f44f-c18056e1210b"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy as dc\n",
        "\n",
        "# prepare data frame to be dateTime | latitude | longitude | reflectivity | reflectivity_1 to _15\n",
        "def prepare_dataframe_for_lstm(df, n_steps):\n",
        "  df = dc(df)\n",
        "\n",
        "  df['datetime'] = pd.to_datetime(df['dateTime'])\n",
        "\n",
        "  # Encode 'datetime' as cyclical features (excluding day encoding)\n",
        "  df['minute_sin'] = np.sin(2 * np.pi * df['datetime'].dt.minute / 60)\n",
        "  df['minute_cos'] = np.cos(2 * np.pi * df['datetime'].dt.minute / 60)\n",
        "  df['hour_sin'] = np.sin(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "  df['hour_cos'] = np.cos(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "  df['month_sin'] = np.sin(2 * np.pi * df['datetime'].dt.month / 12)\n",
        "  df['month_cos'] = np.cos(2 * np.pi * df['datetime'].dt.month / 12)\n",
        "\n",
        "  # Move new columns to the front\n",
        "  new_columns = ['minute_sin', 'minute_cos', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
        "  remaining_columns = [col for col in df.columns if col not in new_columns]\n",
        "  df = df[new_columns + remaining_columns]\n",
        "\n",
        "  df = df.drop(columns=['dateTime'])\n",
        "  df = df.drop(columns=['datetime'])\n",
        "\n",
        "  for i in range(1, n_steps+1):\n",
        "    df[f'reflectivity_{i}'] = df['reflectivity'].shift(i)\n",
        "\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "lookback = 30\n",
        "df = prepare_dataframe_for_lstm(data, lookback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_df = df.iloc[:, 9:]\n",
        "y_df = df.iloc[:, 8:9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reshape data and convert negative numbers to 0\n",
        "\n",
        "X = X_df.to_numpy().reshape(X_df.shape[0], X_df.shape[1], 1)\n",
        "y = y_df.to_numpy().flatten()\n",
        "\n",
        "X[X < 0] = 0\n",
        "y[y < 0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create train, val and test splits\n",
        "\n",
        "train_split = int(X.shape[0] * .8)\n",
        "val_split = int(X.shape[0] * .9)\n",
        "\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_val, y_val = X[train_split:val_split], y[train_split:val_split]\n",
        "X_test, y_test = X[val_split:], y[val_split:]\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(InputLayer((lookback, 1)))\n",
        "model1.add(LSTM(64))\n",
        "model1.add(Dense(8, 'relu'))\n",
        "model1.add(Dense(1, 'linear'))\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "cp = ModelCheckpoint('model1/model1.keras', save_best_only=True)\n",
        "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[cp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model1 = load_model('model1/model1.keras')\n",
        "\n",
        "train_predictions = model1.predict(X_train).flatten()\n",
        "train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train})\n",
        "train_results.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_predictions = model1.predict(X_val).flatten()\n",
        "val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val})\n",
        "val_results.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_predictions = model1.predict(X_test).flatten()\n",
        "X_test_strings = ['[' + ', '.join(str(x[0]) for x in reversed(sample)) + ']' for sample in X_test]\n",
        "test_results = pd.DataFrame(data={'Historical':X_test_strings, 'Actuals':y_test, 'Val Predictions':test_predictions,})\n",
        "test_results.head(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.shape, X_test.flatten().shape, X_test[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
