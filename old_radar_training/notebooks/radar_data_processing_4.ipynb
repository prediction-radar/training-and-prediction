{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpClNkF0MQTD",
        "outputId": "629f9b92-b835-4432-a6a1-9859e26bf5c6"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nRaN7EsWE-Na"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(precision=15)\n",
        "\n",
        "root_dir = \"/Users/trevorwiebe/Ktor/radar_backend/radar_data/\"\n",
        "\n",
        "data = pd.read_csv(root_dir + 'data/combined_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1ppnxhzYN56N"
      },
      "outputs": [],
      "source": [
        "# Setting device\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XmeQ2XVAdNFn"
      },
      "outputs": [],
      "source": [
        "# prepare data frame to be dateTime | latitude | longitude | reflectivity | reflectivity_1 to _15\n",
        "from copy import deepcopy as dc\n",
        "\n",
        "def prepare_dataframe_for_lstm(df, n_steps):\n",
        "  df = dc(df)\n",
        "\n",
        "  df['datetime'] = pd.to_datetime(df['dateTime'])\n",
        "\n",
        "  # Encode 'datetime' as cyclical features (excluding day encoding)\n",
        "  df['minute_sin'] = np.sin(2 * np.pi * df['datetime'].dt.minute / 60)\n",
        "  df['minute_cos'] = np.cos(2 * np.pi * df['datetime'].dt.minute / 60)\n",
        "  df['hour_sin'] = np.sin(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "  df['hour_cos'] = np.cos(2 * np.pi * df['datetime'].dt.hour / 24)\n",
        "  df['month_sin'] = np.sin(2 * np.pi * df['datetime'].dt.month / 12)\n",
        "  df['month_cos'] = np.cos(2 * np.pi * df['datetime'].dt.month / 12)\n",
        "\n",
        "  # Move new columns to the front\n",
        "  new_columns = ['minute_sin', 'minute_cos', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
        "  remaining_columns = [col for col in df.columns if col not in new_columns]\n",
        "  df = df[new_columns + remaining_columns]\n",
        "\n",
        "  df = df.drop(columns=['dateTime'])\n",
        "  df = df.drop(columns=['datetime'])\n",
        "\n",
        "  for i in range(1, n_steps+1):\n",
        "    df[f'reflectivity_{i}'] = df['reflectivity'].shift(i)\n",
        "\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  df = df[['reflectivity'] + [col for col in df.columns if col != 'reflectivity']]\n",
        "\n",
        "  return df\n",
        "\n",
        "lookback = 15\n",
        "df = prepare_dataframe_for_lstm(data, lookback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove rows where all -99\n",
        "# List of the columns reflectivity_1 to reflectivity_15\n",
        "reflectivity_columns = [f'reflectivity_{i}' for i in range(1, 16)]\n",
        "reflectivity_columns.append('reflectivity')\n",
        "\n",
        "# convert all the rows that are less than 0.0 to 0.0\n",
        "df[reflectivity_columns] = df[reflectivity_columns].mask(df[reflectivity_columns] <= 0, 0)\n",
        "\n",
        "# Remove rows where all values in the reflectivity columns are 0.0\n",
        "no_zero_df = df[~(df[reflectivity_columns] == 0.0).all(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9eQvy6VSIRfo"
      },
      "outputs": [],
      "source": [
        "#Split into X and y, and shape correctly\n",
        "X_df = no_zero_df.iloc[:, 7:]\n",
        "y_df = no_zero_df.iloc[:, 0]\n",
        "\n",
        "lat_lon = X_df.iloc[:, [0,1]].to_numpy()\n",
        "time_series_data = X_df.iloc[:, 2:].to_numpy()\n",
        "time_series_data = time_series_data.reshape(X_df.shape[0], 15, 1)\n",
        "time_series_data[time_series_data < 15] = 15\n",
        "lat_lon_repeated = np.repeat(lat_lon[:, np.newaxis, :], 15, axis=1)\n",
        "\n",
        "X = np.concatenate([lat_lon_repeated, time_series_data], axis=2)\n",
        "y = y_df.to_numpy().flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0EB0J8EIRfo",
        "outputId": "96a47cbb-3619-4101-cecc-02fb037eb19e"
      },
      "outputs": [],
      "source": [
        "# Create train, val and test splits\n",
        "\n",
        "train_split = int(X.shape[0] * .8)\n",
        "val_split = int(X.shape[0] * .9)\n",
        "\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_val, y_val = X[train_split:val_split], y[train_split:val_split]\n",
        "X_test, y_test = X[val_split:], y[val_split:]\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "yYfYQ2KIIRfp",
        "outputId": "cf66639f-048c-4eb2-af35-abc271c83399"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# # Use this if starting from scratch\n",
        "# model1 = Sequential()\n",
        "# model1.add(InputLayer((lookback, 3)))\n",
        "# # LSTM layer with 64 units and dropout for regularization\n",
        "# model1.add(LSTM(64, return_sequences=False))  # return_sequences=False because we predict one value\n",
        "# model1.add(Dropout(0.2))  # Helps prevent overfitting\n",
        "\n",
        "# # Dense layer for additional feature extraction\n",
        "# model1.add(Dense(32, activation='relu'))  # Increased neurons for more complexity\n",
        "# model1.add(Dropout(0.2))  # More dropout\n",
        "\n",
        "# # Final output layer (predicting a single value)\n",
        "# model1.add(Dense(1, activation='linear'))\n",
        "\n",
        "# model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BZhwltPXIRfp"
      },
      "outputs": [],
      "source": [
        "model1 = load_model(root_dir + 'model/model4.keras')\n",
        "cp = ModelCheckpoint(root_dir + 'model/model4.keras', save_best_only=True)\n",
        "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcLQN98eIRfp",
        "outputId": "18ddf59f-f988-491f-b2f0-c13801b91f8b"
      },
      "outputs": [],
      "source": [
        "model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4, callbacks=[cp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ac-gJpATIRfp"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-1aw8JrJIRfp",
        "outputId": "dc478fa8-e3ab-4db1-ef23-872dcd9b3afa"
      },
      "outputs": [],
      "source": [
        "print(\"Finished training at \" + datetime.now().strftime('%d/%m/%y %H:%M:%S.%f'))\n",
        "test_predictions = model1.predict(X_test).flatten()\n",
        "third_column = np.flip(X_test[:, :, X_test.shape[2]-1], axis=1)\n",
        "X_test_strings = [' '.join(map(str, row)) for row in third_column]\n",
        "test_results = pd.DataFrame(data={'Historical':X_test_strings, 'Actuals':y_test, 'Val Predictions':test_predictions,})\n",
        "sorted_results = test_results.sort_values(by='Actuals', ascending=False)\n",
        "sorted_results[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
