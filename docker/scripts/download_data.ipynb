{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime, timezone\n",
    "import bs4 as bs\n",
    "import os, shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "root_dir = os.path.dirname(os.getcwd()) + \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_time_window(start_date: datetime, end_date: datetime, minutes: int):\n",
    "    \"\"\"\n",
    "    Returns a random (start, end) datetime tuple within [start_date, end_date],\n",
    "    where the difference between start and end is exactly `minutes`.\n",
    "    \"\"\"\n",
    "    delta = end_date - start_date\n",
    "    max_start = delta.total_seconds() - minutes * 60\n",
    "    if max_start < 0:\n",
    "        raise ValueError(\"Time window is too large for the given range.\")\n",
    "    random_offset = random.uniform(0, max_start)\n",
    "    random_start = start_date + timedelta(seconds=random_offset)\n",
    "    random_end = random_start + timedelta(minutes=minutes)\n",
    "    return random_start, random_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(folder_url, destination_folder, start_time, end_time, granularity_minutes=2):\n",
    "    \"\"\"\n",
    "    Downloads files from folder_url to destination_folder within the time window,\n",
    "    only keeping files at intervals of granularity_minutes.\n",
    "    \"\"\"\n",
    "    file_type = \"npy\"\n",
    "\n",
    "    try:\n",
    "        # Create the destination folder if it doesn't exist\n",
    "        if not os.path.exists(destination_folder):\n",
    "            os.makedirs(destination_folder)\n",
    "\n",
    "        # Delete old files\n",
    "        for filename in os.listdir(destination_folder):\n",
    "            file_path = os.path.join(destination_folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "        # Get the list of files in the folder\n",
    "        response = requests.get(folder_url)\n",
    "        data = bs.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        csv_files = data.find_all(\"a\", href=lambda href: href and href.endswith(f'.{file_type}'))\n",
    "\n",
    "        # Filter files based on time range and granularity\n",
    "        filtered_files = []\n",
    "        last_selected_time = None\n",
    "        for file_name in csv_files:\n",
    "            file_type_filename = file_name['href'].split('/')[-1]\n",
    "            try:\n",
    "                # Parse the filename to extract the creation or modification time\n",
    "                file_time_str = file_type_filename.split('.')[0]  # Extract '20250605-053644'\n",
    "                file_time = datetime.strptime(file_time_str, '%Y%m%d-%H%M%S').replace(tzinfo=timezone.utc)\n",
    "                # Ignore seconds and microseconds for granularity comparison\n",
    "                file_time_rounded = file_time.replace(second=0, microsecond=0)\n",
    "                if start_time <= file_time <= end_time:\n",
    "                    if (last_selected_time is None or \n",
    "                        (file_time_rounded - last_selected_time).total_seconds() >= granularity_minutes * 60):\n",
    "                        filtered_files.append(file_name)\n",
    "                        last_selected_time = file_time_rounded\n",
    "            except ValueError as e:\n",
    "                # Handle parsing errors (e.g., invalid filename format)\n",
    "                print(f\"Error parsing filename: {file_type_filename}, {e.args[0]}\")\n",
    "        if len(filtered_files) == 0:\n",
    "            print(\"No files matching that criteria\")\n",
    "\n",
    "        for file_name in filtered_files:\n",
    "            file_type_url = file_name['href']  # Get the file URL\n",
    "            file_type_filename = file_type_url.split('/')[-1]  # Extract the filename\n",
    "            link = folder_url + file_type_filename\n",
    "            destination_link = os.path.join(destination_folder, file_type_filename)\n",
    "\n",
    "            response = requests.get(link)\n",
    "            with open(destination_link, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "        print(\"Downloading finished, outcome unknown.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading files: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data time window: 2025-06-04 07:24:05.083714+00:00 to 2025-06-04 11:24:05.083714+00:00\n",
      "Validation data time window: 2025-06-05 08:11:06.763740+00:00 to 2025-06-05 10:11:06.763740+00:00\n",
      "Test data time window: 2025-06-04 15:21:48.635249+00:00 to 2025-06-04 17:21:48.635249+00:00\n"
     ]
    }
   ],
   "source": [
    "data_start_time = datetime(2025, 6, 3, 16, 38, tzinfo=timezone.utc)\n",
    "data_end_time = datetime.now(timezone.utc)\n",
    "\n",
    "train_data_start_time, train_data_end_time = random_time_window(data_start_time, data_end_time, 240)\n",
    "validation_data_start_time, validation_data_end_time = random_time_window(data_start_time, data_end_time, 120)\n",
    "test_data_start_time, test_data_end_time = random_time_window(data_start_time, data_end_time, 120)\n",
    "\n",
    "print(f\"Train data time window: {train_data_start_time} to {train_data_end_time}\")\n",
    "print(f\"Validation data time window: {validation_data_start_time} to {validation_data_end_time}\")\n",
    "print(f\"Test data time window: {test_data_start_time} to {test_data_end_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading finished, outcome unknown.\n",
      "Downloading finished, outcome unknown.\n",
      "Downloading finished, outcome unknown.\n"
     ]
    }
   ],
   "source": [
    "# Initiate download of files\n",
    "folder_url = f'http://66.213.177.43/v2_npy_files/'\n",
    "granularity_minutes = 10\n",
    "\n",
    "train_destination_folder = root_dir + f'train_npy_files'\n",
    "download_files(folder_url, train_destination_folder, train_data_start_time, train_data_end_time, granularity_minutes)\n",
    "\n",
    "validation_destination_folder = root_dir + f'validation_npy_files'\n",
    "download_files(folder_url, validation_destination_folder, validation_data_start_time, validation_data_end_time, granularity_minutes)\n",
    "\n",
    "test_destination_folder = root_dir + f'test_npy_files'\n",
    "download_files(folder_url, test_destination_folder, test_data_start_time, test_data_end_time, granularity_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npy files into a list\n",
    "npy_files = sorted(glob(root_dir + 'train_npy_files/*.npy'))\n",
    "npy_files += sorted(glob(root_dir + 'validation_npy_files/*.npy'))\n",
    "npy_files += sorted(glob(root_dir + 'test_npy_files/*.npy'))\n",
    "\n",
    "for i in enumerate(npy_files):\n",
    "    array = np.load(i[1])\n",
    "    \n",
    "    array[array < 20] = 0\n",
    "    array[array > 80] = 80\n",
    "\n",
    "    np.save(i[1], array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading and data processing at 05/06/25 09:04:56.650420\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Finished downloading and data processing at \" + datetime.now().strftime('%d/%m/%y %H:%M:%S.%f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radarenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
