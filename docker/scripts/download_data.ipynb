{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import bs4 as bs\n",
    "import os, shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "root_dir = os.path.dirname(os.getcwd()) + \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading finished, outcome unknown.\n"
     ]
    }
   ],
   "source": [
    "# Downloading file\n",
    "\n",
    "file_type = \"npy\"\n",
    "\n",
    "def download_files(folder_url, destination_folder, start_time, end_time, file_time):\n",
    "\n",
    "  try:\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "      os.makedirs(destination_folder)\n",
    "\n",
    "    # Delete old files\n",
    "    for filename in os.listdir(destination_folder):\n",
    "      file_path = os.path.join(destination_folder, filename)\n",
    "      try:\n",
    "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "              os.unlink(file_path)\n",
    "          elif os.path.isdir(file_path):\n",
    "              shutil.rmtree(file_path)\n",
    "      except Exception as e:\n",
    "          print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "\n",
    "    # Get the list of files in the folder\n",
    "    response = requests.get(folder_url)\n",
    "    data = bs.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    csv_files = data.find_all(\"a\", href=lambda href: href and href.endswith(f'.{file_type}'))\n",
    "\n",
    "    # Filter CSV files based on time range\n",
    "    filtered_files = []\n",
    "    for file_name in csv_files:\n",
    "        file_type_filename = file_name['href'].split('/')[-1]\n",
    "        try:\n",
    "            # Parse the filename to extract the creation or modification time\n",
    "            file_time_str = file_type_filename.split('.')[0]  # Extract '20241021-031240'\n",
    "            file_time = datetime.strptime(file_time_str, '%Y%m%d-%H%M%S')  # Use new format 'YYYYMMDD-HHMMSS'\n",
    "            if start_time <= file_time <= end_time:\n",
    "                filtered_files.append(file_name)\n",
    "        except ValueError as e:\n",
    "            # Handle parsing errors (e.g., invalid filename format)\n",
    "            print(f\"Error parsing filename: {file_type_filename}, {e.args[0]}\")\n",
    "    \n",
    "    if len(filtered_files) == 0:\n",
    "       print(\"No files matching that criteria\")\n",
    "\n",
    "    for file_name in filtered_files:\n",
    "      file_type_url = file_name['href']  # Get the CSV file URL\n",
    "      file_type_filename = file_type_url.split('/')[-1]  # Extract the filename\n",
    "      link = folder_url + file_type_filename\n",
    "      destination_link = os.path.join(destination_folder, file_type_filename)\n",
    "\n",
    "      response = requests.get(link)\n",
    "      with open(destination_link, 'wb') as f:\n",
    "         f.write(response.content)\n",
    "\n",
    "    print(\"Downloading finished, outcome unknown.\")\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading files: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Initiate download of files\n",
    "folder_url = f'http://66.213.177.43/v2_{file_type}_files/'\n",
    "destination_folder = root_dir + f'{file_type}_files'\n",
    "now = datetime.now(timezone.utc)\n",
    "start_time = datetime(2025, 6, 3, 16, 38)\n",
    "end_time = datetime(2025, 6, 3, 17, 40)\n",
    "\n",
    "download_files(folder_url, destination_folder, start_time, end_time, file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npy files into a list\n",
    "npy_files = sorted(glob(root_dir + 'npy_files/*.npy'))\n",
    "\n",
    "for i in enumerate(npy_files):\n",
    "    array = np.load(i[1])\n",
    "    \n",
    "    array[array < 20] = 0\n",
    "    array[array > 80] = 80\n",
    "\n",
    "    np.save(i[1], array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading and data processing at 03/06/25 12:31:31.647273\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Finished downloading and data processing at \" + datetime.now().strftime('%d/%m/%y %H:%M:%S.%f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radarenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
